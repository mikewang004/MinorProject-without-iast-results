{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_qFHr9IhitQ"
   },
   "source": [
    "**Machine Learning assignment 4: dimensionality reduction**\n",
    "\n",
    "Read this notebook and do the exercises; then:\n",
    "\n",
    "* Copy your exercise solutions into the skeleton code in `A4.py`, and you test them with `pytest` and `A4_test.py`. When you're satisfied that your code in `A4.py` passes the tests, commit and push it back to Github. You can also push your notebook -- that will never negatively impact your grade, but could give us an idea of what you did wrong for open questions.\n",
    "\n",
    "* Make a PDF report answers to the open questions (as well as your graphics). It should be named `A4_s1234567890.pdf`, but using your own student number instead of 1234567890. Hand the PDF report in through Brightspace. Your answers don't need to be long, just be to the point -- _but illustrative examples are welcome._\n",
    "\n",
    "* If you do not submit both `A4.py` to Github and the PDF report to Brightspace, you will fail this assignment.\n",
    "\n",
    "* This is an individual assignment. Your code and report must be your own work.\n",
    "\n",
    "---\n",
    "\n",
    "Specific notes for this assignment:\n",
    "\n",
    "* Make sure to look at the code that is not part of programming exercises, we sometimes give it to you because you need it later on.\n",
    "\n",
    "* There are 8 programming exercises that are labelled with subsubsections that start with \"Exercise [number]:\".\n",
    "\n",
    "* There are 5 regular open questions, 2 plot questions, and 1 open bonus question that you should answer in your report. These are labelled with subsubsections that start with \"Question [number] [(bonus)  or (2 points) if applicable]:\".\n",
    "\n",
    "* The 8 programming exercises (`A4.py`) make up 40% of your grade. The 8 or 9 questions that end up in your report (`A4_[your ID].pdf`) make up the other 60% of your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcbMOtMvwSnl"
   },
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwnovVS-baoG"
   },
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-DLYyhnkwSnw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale as sk_scale\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle as sk_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdW8IqR7bP6w"
   },
   "source": [
    "## Define some basic functions and classes\n",
    "\n",
    "There are examples of usage of all of these below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kYnzzLgNymPR"
   },
   "outputs": [],
   "source": [
    "def helpful_eq(a, b, failing_is_good=False):\n",
    "    \"\"\"Basically `==` after rounding with prints. \n",
    "    `a` and `b` can be numbers or (>1D) (NumPy) arrays.\"\"\"\n",
    "    def print_bad_news():\n",
    "        print(a)\n",
    "        print(\"helpful_eq(...) fail: ^ does not equal:\")\n",
    "        print(b)\n",
    "\n",
    "    try:\n",
    "        if hasattr(a, \"__len__\"):\n",
    "            r = np.allclose(a, b, atol=1e-3)\n",
    "        else:\n",
    "            r = round(a, 3) == round(b, 3)\n",
    "        if failing_is_good:\n",
    "            r = not r\n",
    "        if not r:\n",
    "            print_bad_news()\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print_bad_news()\n",
    "        print(\"And/or we encountered exception message\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "def mean_squared_error(true, pred):\n",
    "    \"\"\"`true` and `pred` should be (numpy.nd)arrays with similar shapes.\n",
    "    Returns mean (over instances/rows) of sum of squared feature difference (in columns).\"\"\"\n",
    "    return np.mean(((true - pred) ** 2).mean(axis=1))\n",
    "\n",
    "\n",
    "class NFolds:\n",
    "    def __init__(self, X, y, n_folds=5, seed=42):\n",
    "        \"\"\" Initialize the KFolds instance\n",
    "\n",
    "        :param X: numpy.ndarray of feature columns \n",
    "        :param y: numpy.ndarray of labels\n",
    "        :param n_folds: number of folds desired\n",
    "        :param seed: random seed, if you want reproducible results (optional)\n",
    "\n",
    "        After initialization, self.folds will store n_folds folds.\n",
    "        Each fold is a pair of arrays with training indices and test indices.\n",
    "        The folds are as evenly distributed in size as possible.\n",
    "        All the test segments are pairwise disjoint.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_folds = n_folds\n",
    "        self.folds = []\n",
    "        indices = np.arange(X.shape[0])\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed=seed)\n",
    "        np.random.shuffle(indices)\n",
    "        fold_size = X.shape[0] / n_folds\n",
    "        for fold_num in range(n_folds):\n",
    "            test = indices[int(fold_num * fold_size): int((fold_num + 1) * fold_size)]\n",
    "            train = np.concatenate([indices[: int(fold_num * fold_size)],\n",
    "                                    indices[int((fold_num + 1) * fold_size):]])\n",
    "            self.folds.append((train, test))\n",
    "\n",
    "    def get_fold(self, fold_num):\n",
    "        \"\"\" Get the training and test data of the fold_num-th fold\n",
    "\n",
    "        :param fold_num: Which fold's division of the data to use\n",
    "        :return: Training and test features/labels\n",
    "        \"\"\"\n",
    "        train, test = self.folds[fold_num]\n",
    "        X_train = self.X[train]\n",
    "        X_test = self.X[test]\n",
    "        y_train = self.y[train]\n",
    "        y_test = self.y[test]\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_X3cHfqwSnx"
   },
   "source": [
    "# Principal component analysis\n",
    "\n",
    "Principal component analysis (PCA) is an unsupervised method for dimensionality reduction. The principal _components_ are vectors that can be considered as a direction in which the data is most variant. The first of these components \"explains\" more variance in the data than the second, and so forth. The _scores_ are numbers (\"scalars\") with which these components can be multiplied to reconstruct the original data. By taking only $k$ $d$-dimensional component vectors and an $n\\times k$ score matrix we have a compressed _approximate_ representation of an $n\\times d$-sized dataset. The information density of all involved numbers/vectors is hopefully higher.\n",
    "\n",
    "We will use the singular value decomposition to implement our principal component analysis algorithm -- it is described around equation 10.2 on page 324 (344 in my .pdf) of Peter Flach's Machine Learning book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-rb8nH3wSny"
   },
   "source": [
    "## Load simple numerical dataset\n",
    "\n",
    "Our simple, first dataset consists of four instances of measurements of two features. In terms of the mathematical symbols: this is our $n \\times d = 4 \\times 2$-sized matrix $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ucRE1KSpwSny"
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.0, 0.4], \n",
    "              [1.0, 2.0], \n",
    "              [2.0, 3.2], \n",
    "              [3.0, 5.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RranDBzrwSnz"
   },
   "source": [
    "\n",
    "## Center and scale\n",
    "\n",
    "We need to normalize our dataset if we want PCA to consider all features potentially equally important. Specifically, we want all $d$ features to be centered on zero and have the same standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmli24BGg5iR"
   },
   "source": [
    "### Exercise 1: implement `(un)center_and_(un)scale`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oGHsooLvwSn0"
   },
   "outputs": [],
   "source": [
    "def center_and_scale(X):\n",
    "    \"\"\"`X` is a numpy.ndarray. Rows represent instances. Columns represent feature values.\n",
    "    First output is a modified copy of `X` where mean of individual features is 0 and \n",
    "    standard deviation is 1. The second and third output are original values of said mean and \n",
    "    standard deviation respectively.\"\"\"\n",
    "    orig_mean = np.mean(X, 0)\n",
    "    orig_std = np.std(X, 0)\n",
    "    #Normalise dataset\n",
    "    \n",
    "    X_transform = X - orig_mean\n",
    "    #X_normalised = (X_transform)/(np.linalg.norm((X_transform),axis=0))*np.sqrt(X.shape[0])\n",
    "    X_normalised = X_transform / orig_std\n",
    "    \n",
    "    return X_normalised, orig_mean, orig_std\n",
    "\n",
    "\n",
    "def uncenter_and_unscale(X_norm, orig_center, orig_std):\n",
    "    \"\"\"`X_norm` is a numpy.ndarray. Rows represent instances. Columns represent feature values,\n",
    "    now with mean 0 and standard deviation 1. Output is a modified copy of `X_norm` with values of\n",
    "    `orig_center` as column means and values of `orig_std` as column standard deviations. (This\n",
    "    function thus reverses `center_and`scale`.)\"\"\"\n",
    "    #raise NotImplementedError()\n",
    "    #X_transform = X + orig_center \n",
    "    #X_orig = X_transform * ((X_transform.shape[0])**2 * np.linalg.norm((X_transform),axis=0))\n",
    "    \n",
    "    X_orig = (X_norm * orig_std) + orig_center\n",
    "    return X_orig\n",
    "\n",
    "X_norm, orig_center, orig_std = center_and_scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uv1YeSa4n53r"
   },
   "outputs": [],
   "source": [
    "def test_center_and_scale():\n",
    "    # And uncenter_and_unscale...\n",
    "    X = np.array([[0.0, 0.5, 7], [1.0, 1.5, -10], [2.0, 4.5, 0], [3.0, 5.5, 999]])\n",
    "    X_norm, orig_center, orig_std = center_and_scale(X)\n",
    "    assert helpful_eq(X_norm.mean(), 0)\n",
    "    assert helpful_eq(X_norm.var(), 1)\n",
    "    sk_X_norm = sk_scale(X)\n",
    "    assert helpful_eq(X_norm, sk_X_norm)\n",
    "    assert helpful_eq(orig_center, [1.5, 3.0, 249.])\n",
    "    assert helpful_eq(orig_std, [1.118, 2.062, 433.055])\n",
    "    X = np.dot(np.random.rand(2, 2), np.random.randn(2, 100)).T\n",
    "    csX = center_and_scale(X)\n",
    "    assert helpful_eq(csX[0], sk_scale(X))\n",
    "    assert helpful_eq(uncenter_and_unscale(*csX), X)\n",
    "\n",
    "test_center_and_scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8b1PgAewSn5"
   },
   "source": [
    "## Visualize our goal\n",
    "\n",
    "Using https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html. You can use this cell as inspiration for the other programming exercises if you didn't manage to finish the earlier ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1618830275489,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "",
      "userId": "13006621849040554927"
     },
     "user_tz": -120
    },
    "id": "zHGGtCELwSn5",
    "outputId": "e11879f1-2781-4d5b-afc1-372d88063a9e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component(s) matrix:\n",
      "[[0.70710678 0.70710678]]\n",
      "Score matrix\n",
      "[[-1.86816932]\n",
      " [-0.60294921]\n",
      " [ 0.50407975]\n",
      " [ 1.96703879]]\n",
      "\n",
      "[[-1.342 -1.3  ]\n",
      " [-0.447 -0.405]\n",
      " [ 0.447  0.266]\n",
      " [ 1.342  1.44 ]]\n",
      "Recreation of [centered and scaled matrix above] using 1 component(s):\n",
      "[[-1.321 -1.321]\n",
      " [-0.426 -0.426]\n",
      " [ 0.356  0.356]\n",
      " [ 1.391  1.391]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002882207412825675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "sk_pca = PCA(n_components=k)\n",
    "sk_X_norm = sk_scale(X)\n",
    "sk_score = sk_pca.fit_transform(sk_X_norm)\n",
    "sk_components = sk_pca.components_\n",
    "X_norm_reconstr = sk_score @ sk_components  # @ is a standard matrix multiplication\n",
    "\n",
    "\n",
    "\n",
    "print(\"Component(s) matrix:\")\n",
    "print(sk_components)\n",
    "print(\"Score matrix\")\n",
    "print(sk_score)\n",
    "print()\n",
    "print(sk_X_norm.round(3))\n",
    "print(f\"Recreation of [centered and scaled matrix above] using {k} component(s):\")\n",
    "print(X_norm_reconstr.round(3))\n",
    "mean_squared_error(sk_X_norm, X_norm_reconstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFOJUNrmymPX"
   },
   "source": [
    "\n",
    "### Question 1: why can the two-dimensional data we stored in `X` be reconstructed so well using only one principal component?\n",
    "\n",
    "This is because the principal component stores the relation between the two values belonging to each point in X, and because the matrix was rescaled and recentered before the principal component was calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usWY5XLAn53y"
   },
   "source": [
    "## Singular value decomposition\n",
    "We use https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html for most of $\\mathbf{X} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{\\mathrm{T}}$, where $\\mathbf{U}$ is an $n\\times r$ matrix, $\\mathbf{\\Sigma}$ is an $r\\times r$ matrix, and $\\mathbf{V}$ is a $d \\times r$ matrix. We simplify and assume $d = r < n$ as in the book, which is practically fine but really not in line with the classical definition of an SVD. The NumPy function sort of works with this assumption/simplification as well, but goes further by returning only the diagonal elements of $\\mathbf{\\Sigma}$.\n",
    "\n",
    "The `R_squared` variable contains the amount of variance the corresponding principal component \"explains\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "error",
     "timestamp": 1618830362642,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "",
      "userId": "13006621849040554927"
     },
     "user_tz": -120
    },
    "id": "5516tMyZn53z",
    "outputId": "08a69547-f5d9-45e3-c523-acd5a4e836f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66145151 -0.19228027]\n",
      " [-0.21348261 -0.19431549]\n",
      " [ 0.17847649  0.8454258 ]\n",
      " [ 0.69645762 -0.45883004]]\n",
      "[[2.82434813 0.        ]\n",
      " [0.         0.15184749]]\n",
      "[2.82434813 0.15184749]\n",
      "[[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "[0.9971177925871744, 0.0028822074128256807]\n"
     ]
    }
   ],
   "source": [
    "U, Sigma_elements, V_transpose = np.linalg.svd(X_norm, full_matrices=False)\n",
    "Sigma = np.zeros((U.shape[1], V_transpose.shape[0]))\n",
    "Sigma[:Sigma_elements.size, :Sigma_elements.size] = np.diag(Sigma_elements)\n",
    "S_squared_sum = sum(S_i ** 2 for S_i in Sigma_elements)\n",
    "R_squared = [S_i ** 2 / S_squared_sum for S_i in Sigma_elements]\n",
    "print(U)\n",
    "print(Sigma)\n",
    "print(Sigma_elements)\n",
    "print(V_transpose)\n",
    "print(R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHPuecBDwSn3"
   },
   "source": [
    "## Obtain $k$ principal components and score matrix\n",
    "\n",
    "https://en.wikipedia.org/wiki/Principal_component_analysis#Singular_value_decomposition and some other sources call the $k$ principal components $\\mathbf{W}_k$ and the corresponding score matrix $\\mathbf{T}_k$. The book calls the score matrix $\\mathbf{W}$ and the components $\\mathbf{V}$, which makes more sense if we name the variables in our singular value decomposition as in $\\mathbf{X} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{\\mathrm{T}}$. \n",
    "\n",
    "We will just name the $k\\times d$ principal components matrix \"components\" and the $n\\times k$ score matrix \"score\" so that we don't keep working with unidiomatic variables. The components matrix can be multiplied with the score matrix to create a reconstruction of $\\mathbf{X}$. Here's an even bigger hint: the components are somewhere in $\\mathbf{U}\\mathbf{\\Sigma}$ and the score matrix can be found in $\\mathbf{V}^{\\mathrm{T}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4i4nhTMhel5"
   },
   "source": [
    "### Exercise 2: implement `svd_to_components_and_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "xkJV0UqAwSn3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component(s) matrix:\n",
      "[[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "Score matrix\n",
      "[[-1.86816932 -0.02919728]\n",
      " [-0.60294921 -0.02950632]\n",
      " [ 0.50407975  0.12837578]\n",
      " [ 1.96703879 -0.06967219]]\n"
     ]
    }
   ],
   "source": [
    "def svd_to_components_and_score(U, Sigma_elements, V_transpose, k):\n",
    "    \"\"\" Input is output of `numpy.linalg.svd(..., full_matrices=False)` and `k` indicating # of \n",
    "    components. First output is `k`-by-d component numpy.ndarray; second output is n-by-`k` score \n",
    "    numpy.ndarray.\n",
    "    \"\"\"\n",
    "    # U dim n x r; Sigma dim r x r; V dim d x r. \n",
    "    # component dim k x d; score dim n x k \n",
    "    # d = r < n => U dim n x d; Sigma dim d x d = V dim \n",
    "    # USigma dim n x d \n",
    "    Sigma[:Sigma_elements.size, :Sigma_elements.size] = np.diag(Sigma_elements)\n",
    "    USigma = U @ Sigma\n",
    "    components = V_transpose[:k, :]\n",
    "    score = USigma[:, :k]\n",
    "    return components, score\n",
    "\n",
    "components, score = svd_to_components_and_score(U, Sigma_elements, V_transpose, k)\n",
    "print(\"Component(s) matrix:\")\n",
    "print(components)\n",
    "print(\"Score matrix\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Rb7-isB7ymPa"
   },
   "outputs": [],
   "source": [
    "def test_svd_to_components_and_score():\n",
    "    for k in [1, 2]:\n",
    "        X = sk_scale(np.array([[0.0, 0.4],\n",
    "                               [1.0, 1.6],\n",
    "                               [2.0, 2.4],\n",
    "                               [3.0, 3.6]]))\n",
    "        U, S, V_transpose = np.linalg.svd(X, full_matrices=False)\n",
    "        components, score = svd_to_components_and_score(U, S, V_transpose, k)\n",
    "        assert helpful_eq(components[0, 0], 0, failing_is_good=True)\n",
    "        assert helpful_eq(components[0, 0], components[0, 1])\n",
    "        assert helpful_eq(score[0, 0], -score[3, 0])\n",
    "        assert helpful_eq(score[1, 0], -score[2, 0])\n",
    "        np.random.seed(39)\n",
    "        X = sk_scale(np.dot(np.random.rand(2, 2), np.random.randn(2, 100)).T)\n",
    "        sk_pca = PCA(n_components=k)\n",
    "        sk_score = sk_pca.fit_transform(X)\n",
    "        sk_components = sk_pca.components_\n",
    "        U, S, V_transpose = np.linalg.svd(X, full_matrices=False)\n",
    "        components, score = svd_to_components_and_score(U, S, V_transpose, k)\n",
    "        assert helpful_eq(sk_components, components)\n",
    "        assert helpful_eq(sk_score, score)\n",
    "\n",
    "\n",
    "test_svd_to_components_and_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwhmjnYXwSn4"
   },
   "source": [
    "## Reconstruct our data using $k=1$ principal components\n",
    "\n",
    "If you don't have `orig_center` and `orig_std`, you can compare `X_norm` with its reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iVgVzucewSn4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.4]\n",
      " [1.  2. ]\n",
      " [2.  3.2]\n",
      " [3.  5.3]]\n",
      "Recreation of [matrix above] using 1 components:\n",
      "[[0.023 0.363]\n",
      " [1.023 1.963]\n",
      " [1.899 3.362]\n",
      " [3.055 5.212]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0028822074128256755"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "print(f\"Recreation of [matrix above] using {k} components:\")\n",
    "X_norm_reconstr = score @ components\n",
    "X_reconstr = uncenter_and_unscale(X_norm_reconstr, orig_center, orig_std)\n",
    "print(X_reconstr.round(3))\n",
    "mean_squared_error(X_norm, X_norm_reconstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP9TzzY7Fsr4"
   },
   "source": [
    "### Question 3: make a scatter plot that contains true and reconstructed values $(k=1)$, as well as the single principal component.\n",
    "\n",
    "It is easiest to use the centered and scaled versions of `X` and its reconstruction. You can optionally scale the component visualization with `R_squared` as follows. That is not so informative with $k=1$ but it might be nice to try with $k=2$. Here is some code that you can probably use to get an idea of how:\n",
    "\n",
    "```\n",
    "for i in range(k):\n",
    "    horizontal = R_squared[i] * components[i, 0]\n",
    "    vertical = R_squared[i] * components[i, 1]\n",
    "    plt.arrow(0, 0, horizontal, vertical, head_width=0.05, color=\"red\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Av-I5E4lFuNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x272e0f4e708>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAEWCAYAAACOk1WwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1lElEQVR4nO3deXhU5fn/8fdNCIKCoIKyymIBFRICRgS1oqKgonX5umsLWqWgVGorirVFfmitLdatdcOlKFoBN7SCGyooVSuLLGJFEVHCIouAAkEB798f5yROhplksk5y8nldV67MWeY599me+2xzHnN3REREJJrqpDsAERERqTxK9CIiIhGmRC8iIhJhSvQiIiIRpkQvIiISYUr0IiIiEVYrEr2ZuZn9JN1xRJGZjTezmyuh3BlmdllFl1tWZtbZzD4ws2/N7KoKLrtduI3Wrchyayozu9/M/ljM8NFm9ng5yj/WzPLK+v1STGeLmXWogHIGmdmsiogphWkdGMadUc5yil2HpShH+0YFKDbRhyu84O8HM8uP6b6oqoKszcxsuZmdUInl6yAoNdcCM9y9kbvfna4gqjBJlTgdM3vGzMbF9ZtiZv8oz7TdfYi735RqHCVJ1zbu7g3dfVlVT7c83P3LMO5d5SyncB1K5ShNbig20YcrvKG7NwS+BE6L6fdEzAQjcbRlgRp1lSMqy74GaAssTncQ1cyVwP+Z2XEAZnYe0B0YmdaopExUl0SYu6f0BywHTgg/HwvkAdcBa4AJwCBgVtx3HPhJ+HkP4DaCA4avgPuBBkmmdRDwBrABWA88ATSJi+UaYCGwGZgE1I8ZPgJYDawCLo2NI8G0ZgB/Av4D5AM/AQ4GXgO+BpYA58aM3wD4G/BFOO1ZBfMB/IwgGWwKyz0klZiBpsCL4fe+Bt4mOAibAPwQxrWF4KyyXTg/vwyX5VsF66OY9ZUB/B74DPgWmAu0Cb/rwNaw/PPC8U8F5ofxvANkx5TbHZgXljMJmAjcnGC57hF+v2tMv2bhvOwP7BPO8zpgY/i5ddx6uSz8PBp4PGZYwTKoG3Y3Bh4O1/lK4GYgIxz2E2BmuMzXA5OK2cYTrj+CbXEXsD1cTp0SfPcS4H/hclkG/KqY6WQQ7Avrw3GvjJufhGUBe4XL74cwji1AS6An8G4Y92rgH0C98DsG3AGsDZfBwoJ1QpJ9Mtl0kszLIGApcGBYxklJxqsfltk07P4DsBPYO+y+Gbgz/Dw+7E42v6OBycBj4TJaDOQmme5u2zg/1l+/C5fLauCSuG031boq6fZF0fpvPHAPMDWM+b/AQTHj9iOoazYD94ZlXhazjGfFjJu0fkpSv/0ZeD8s+3lg37j9KLYuKehXN+b7NxHUj98Crxasw3D40QR1xCZgBTAodh3G5Yvfh8toOXBRTBkDgA+Ab8IyRifb1xPMXxvgWYJ6ZAPwj7B/HYJt7ItwHT8GNI4r85JwehuBIcDhBPvHpoJyYpb/f4C/h8vwY6BvzPCWwAvh+lgKXB4zbDTFbKvhd58J4/8cuCqV75IgNyTbBty9XIl+J/AXgp2iASUn+jvDhbEv0Aj4N/DnYnaeE8OymxFsgHfGxfJ+uJD2JagUh4TDTiLYObsSVBT/ouRE/yXQBahLkDRWhBtBXaAHwcbZJRz/nvA7rQgq7CPDODsRVCYnApkESXkpP1a4xcX8Z4LKJDP8+ylg8cs9biN9LJy/BpSc6EcAi4DOBBV/N2C/+HUUdvcg2DGOCOdvYFjWHkA9gh3n6jDOs4EdJEj0YVmPAH+K6b4SeDn8vB/wf8Ce4fbwFDAlbr2kmuinAA+Ey2P/cDkXJMcngRsIdvz6wNFJYi1p/RXGk+T7AwgOUA3oA2wDeiQZdwhBZdEm3BbejJufpGUlWdeHAb0Ittd2BNvWb8Jh/QkO7JqE5R0CtChpn0w0nWLm/RWCfeTREsZ7C/i/8POrBAeeJ8cMOzP8PJ64JBFXzmiCg65TCLbRPwPvFTPd+G38WIL6a0y4rk8Jl/E+Zairkm5f7J7ovyY4KKtLcPIyMRzWlCDJnRUOG06wX+2W6Am28aT1U5L6bSU/1ofPEO5LJK5LCvrFJvrPCPaPBmH3reGwAwkS0AXhctwPyEmyDncCtxPUI30I9rXOMcOzwmWYTVB/n5FoX4+btwxgAcGB7F6xy5/gBG8p0AFoSHAwMCGuzPvD7/Qj2J6mENQfrQjqwD4xy38nP9Z75xEk/IIDppkEB2f1gRyCpN23pG01nN+5wCiCurUDwYF9/1S2c+JyQ7H7XiojxRcarpjvKXoWPYgkiZ6ggtlK0SPY3sDnKU77DOCDuFgujun+K3B/+PkRwg0x7O5EyYl+TEz3ecDbceM8ANwYrph8oFuCcv4ITI7prkOwgx2bQsxjCI60d4sxfmXy40baIa7iKi7RLwFOT7ESvA+4KW6cJQQ75zEEV0ksZtg7JE/0JwDLYrr/A/wiybg5wMa49VJiogcOAL4j5oyLoOJ5M/z8GDCOmKsFSaZf0vorjCfFbXYKMDzJsDcID/LC7n4Uf9ZSWFaidZ1g/N8Az4Wfjwc+ITgQqBMzTrH7ZCrTifneH8L4TyxhvJuAu8P1toYgod3K7mf74yk50U+P6T4UyC9muokSfX7s8iao2HuVtFwSlJ10+2L3RP9QzLBTgI/Dz78A3o1bNytInOiT1k9J4ptB0frwUIK6O4PEdUlBv9hE/4eY4Vfw48H69QXbWYLpxq/DncBeMcMnA39M8t07gTsSxRM3Xm+CpJpo2OvAFTHdnQkOnurGlNkqZvgGwiuaYfcz/HiwPIjd6733gZ8THKzvAhrFDPszML6kbZXgZOrLuLivB/6ZynZOKRJ9ee5Hr3P37SmO24zgzG2umW0ys03Ay2H/3ZjZ/mY20cxWmtk3wOMER72x1sR83kZw1AbBGfOKmGFfpBBf7PhtgSMK4gxjvQhoHsZQn+AIN17L2Gm5+w9hua1SiHkswdHnq2a2zMxSuce5ouRRCrVJEnMibYHfxc1/G4L5awms9HArCxW3fN8AGpjZEWbWliCZPwdgZnua2QNm9kW4jt8CmpThad+2BEfZq2PifYDgyByCM3MD3jezxWZ2aZJyUll/SZnZyWb2npl9HcZwCrtvs7HTSrqNlrIszKyTmb1oZmvCZXlLwfju/gbBpfx7gK/MbJyZ7U0p98lipt2R4JbUvcDfzCyzmNFnElT6PQiuML1GcADZC1jq7utLMen4fal+Ke8xb3D3nXFlNKT0yyXV7StRzAnrrHD/SvYAYnH1UzLx21omRbenkuqSZHGXpl7Z6O5b4+JoCRDWD2+a2Toz20xwxSvp9h6jDfBF3HosUGR/Dj8XnBgU+Crmc36C7oYx3YnqvYI68Wt3/zZuWHH1fsG22hZoGbcufx8XY3m3c6B8P6/zuO6tBDsIAGYWu+GtJ1hwXdy9SfjX2IOH/BL5c1h+trvvDVxMsDOlYjXBBlDgwBS+EzsvK4CZMXE28eDhw6HhfGwnuKwabxXBigOCB/vCOFaWOHH3b939d+7eATgN+K2Z9U0QW7KY45d9BkUrphVJYk5kBcHl9tj539PdnyRYtq3CeSuQdPmGyXIywRn2hcCLMTvE7wiOso8I1/ExBeEnKKrI/FG0UltBcEbfNCbevd29SxjDGne/3N1bAr8C7k3yBHaZ15+Z7UFwBnAbcIC7NwGmJZkXKGYbTaGsRNvDfQS3AjqGy/L3sdN297vd/TCC21OdCG7llLRPJtvuYufbgIcIzsB+TbCerivmK+8QrPMzCfaxj8J5H0BwEJBIiXFUsFLVVaXYvoqzGmhd0BEu19ZJxi2ufkomflvbQTCfhbNRynhjY0m1XtnHzPaKi2NV+PlfBLdK2rh7Y4JL6qnU9yuAA5MkviL7czi9nRRN5qWRqN5bFf7ta2aN4oaVWG8QxP953Lps5O6npBhTyuutIp8wXwB0MbMcM6tPcNkhiCao8B8E7jCz/QHMrJWZ9U9SViOCBww2mVkrgoopVZOBQWZ2qJntSXDJvTReBDqZ2c/NLDP8O9zMDgnn4xHgdjNraWYZZtY7rJwnAwPMrG94VvM7ggT0TkkTNLNTzewn4Yb0DcGloIKft3xFcO+mOJ8QHOkNCKf9B4J7YQUeAm4ys47hLwuyzWy/JOU/CAwJj7LNzPYKy21E8MDXTuAqM6trZmcR3HMszr8ILjdeFH4u0IigQt1kZvtS/HqaDxxjwW98GxNc3gLA3VcT3O/9m5ntbWZ1zOwgM+sDYGbnmFlBpbmRYOdI9NOhMq8/gvtrexBcRtxpZicTXI5PZjLBMmxtZvtQ9Cn1ksr6CtgvXA4FGhFsN1vM7GCgsNIPt90jwnnaSnCguiuFfTLRdOINJTjzuiUs75fAtWEMu3H3bQT3JK/kx8T+DkGCTJboU4mjJKnsQwUxlqquKsX2VZypQJaZnREmrStJfoaetH4qpvyLY+rDMcDTXs6fz4WeAE4ws3PD+mA/M8spZvz/Z2b1zOynBA/8PhX2b0RwVrzdzHoSnBSk4n2Cg6Rbw3qqvpkdFQ57ErjazNqbWUOCq1yTkpz9p2J/gn0208zOIXjWZZq7ryDYhv8cTj+bYD94opiyYuP/xsyuM7MGYT7pamaHpxhTytt1hSV6d/+EYCOaDnxK8DR6rOsILk+/Z8HlxekER/eJ/D+Cy3ubCXaCZ0sRx0sEZxhvhNN7I+WZCL7/LUHFej7B0doafnzoEILLlIuA2QQP1/yF4N7nEoIrD38nOFo+jeDniN+nMNmOBMtjC0EyvdfdZ4TD/gz8wYJLO9ckiXkzwb2zhwiOJLdS9NLf7QTJ5VWChPAwwYM1EByQPRqWf667zwEuJ7jcu5FgGQ4Kp/M9wQNDg8Jh51HCunH3/4bxtAReihl0ZxjDeuA9gsujycp4jeAJ/4UEieLFuFF+QZAgPwrjehpoEQ47HPivmW0hOGsY7u6fJ5hGmddfuM1cRbCMNxJUVC8U85UHCR5gW0DwC4bCZVhSWe7+MUEltixcZy0JtskLCR6MepBgWRXYO+y3keCS4gaCqwVQzD6ZZDqFzKwNQeX5y4JlFJ6h/w14MO7sJ9ZMgkvH78d0NyK4dbObkuJI0WhitvEUxi9NXZXS9lWc8JbFOQTP7WwguBc7h+BAM37ckuqnRCYQ3DNfQ3DrsUJe+OTuXxLcVvodQV04n+BB30TWEGyDqwiS4JBw3UJQd40xs28JHkybnOL0dxHspz8heKA6j6BOguCEbALBdvU5wQHur1Ofu938l6CeXk/wK62z3X1DOOwCgvv+qwhuTd4Y1lmpxp8TxrieoA5P9aC2xNxQoODJbhERqQYseJdHHsFP0N4sZ1kzCB5kfagiYitjDMeGMSS7HVGtmdkgggcjj053LGVVo14OIyISRWbW38yahLcBC56xeC/NYUlEKNGLiKRfb4In2AtuG53h7vnpDUmiQpfuRUREIkxn9CIiIhGmRgwqSdOmTb1du3bpDkNEpMaYO3fuencv1UubpGRK9JWkXbt2zJkzJ91hiIjUGGaWyptMpZR06V5ERCTCan2iN7NHzGytmX2YZPixZrbZzOaHf6OqOkYREZGy0qX74I1R/yBohSqZt9391KoJR0REpOLU+kTv7m+ZWbuqmNaOHTvIy8tj+/ZUG/0Tib769evTunVrMjOLa/hORMqq1if6FPU2swUE7zK+xt0XJxrJzAYDgwEOPHD3Rt3y8vJo1KgR7dq1I/mrwEVqD3dnw4YN5OXl0b59+3SHIxJJSvQlmwe0dfctZnYKMIWgcYPduPs4YBxAbm7ubm8i2r59u5K8SAwzY7/99mPdunXpDkVKYcoHKxn7yhJWbcqnZZMGjOjfmTO6tyr5i5IWtf5hvJK4+zfuviX8PA3INLOmZS1PSV6kKO0TNcuUD1Zy/bOLWLkpHwdWbsrn+mcXMeWDVJpgl3RQoi+BmTUvaHIzbCu5DkFTkiIitc7YV5aQv6Noc/b5O3Yx9pUlaYpISlLrE72ZPUnQBnxnM8szs1+a2RAzGxKOcjbwYXiP/m7gfK+hDQSsWLGC9u3b8/XXXwOwceNG2rdvzxdfVO93VBx77LGFLx865ZRT2LRpU7nKW758OV27dq2AyERqn1WbEre1k6y/pF+tv0fv7heUMPwfBD+/q/HatGnD0KFDGTlyJOPGjWPkyJEMHjyYtm3bVto0d+7cSd26FbeZTZs2rcLKEpHSa9mkASsTJPWBDd+HO66DzXnQuDX0HQXZ56YhQolX68/oq7MpH6zkqFvfoP3IqRx16xsVcg/s6quv5r333uPOO+9k1qxZ/O53vyvxOw0bNuSGG26gW7du9OrVi6+++gqAL774gr59+5KdnU3fvn358ssvARg0aBC//e1vOe6447juuusYNGgQQ4cO5bjjjqNDhw7MnDmTSy+9lEMOOYRBgwYVTmfo0KHk5ubSpUsXbrzxxoSxtGvXjvXr17N161YGDBhAt27d6Nq1K5MmTQJg7ty59OnTh8MOO4z+/fuzevXqwv7dunWjd+/e3HPPPeVZhCK12oj+nWmQmVGk39n13uEPfj9sXgF48P/fV8HCyekJUopQoq+mKuuBl8zMTMaOHcvVV1/NnXfeSb169Ur8ztatW+nVqxcLFizgmGOO4cEHHwRg2LBh/OIXv2DhwoVcdNFFXHXVVYXf+eSTT5g+fTp/+9vfgOA2wRtvvMEdd9zBaaedxtVXX83ixYtZtGgR8+fPB+BPf/oTc+bMYeHChcycOZOFCxcmjenll1+mZcuWLFiwgA8//JCTTjqJHTt28Otf/5qnn36auXPncumll3LDDTcAcMkll3D33Xfz7rvvlnXRiQhwRvdW/PmsLFo1aYABrZo0YMxez1B3V9z7QXbkw+tj0hKjFKVEX01V5gMvL730Ei1atODDDxO+9Xc39erV49RTgxcDHnbYYSxfvhyAd999lwsvvBCAn//858yaNavwO+eccw4ZGT8e9Z922mmYGVlZWRxwwAFkZWVRp04dunTpUlje5MmT6dGjB927d2fx4sV89NFHSWPKyspi+vTpXHfddbz99ts0btyYJUuW8OGHH3LiiSeSk5PDzTffTF5eHps3b2bTpk306dOnMFYRKbszurfiPyOP5/NbB/CfkcezZ/6axCNuzqvawCShWn+PvrqqrAde5s+fz2uvvcZ7773H0Ucfzfnnn0+LFi2K/U5mZmbhT6AyMjLYuXNnwvFifya11157FRm2xx57AFCnTp3CzwXdO3fu5PPPP+e2225j9uzZ7LPPPgwaNKjYNwh26tSJuXPnMm3aNK6//nr69evHmWeeSZcuXXY7a9+0aZN+wiVSmRq3Di/bJ+gvaacz+mqqZZMGpeqfCndn6NCh3HnnnRx44IGMGDGCa665pnD4wQcfXKryjjzySCZOnAjAE088wdFHH13m2L755hv22msvGjduzFdffcVLL71U7PirVq1izz335OKLL+aaa65h3rx5dO7cmXXr1hUm+h07drB48WKaNGlC48aNC684PPHEE2WOU0QS6DsKMuPqpswGQX9JO53RV1Mj+nfm+mcXFbl83yAzgxH9O5e5zAcffJADDzyQE088EYArrriC8ePHM3PmTLp06UJpfzV49913c+mllzJ27FiaNWvGP//5zzLH1q1bN7p3706XLl3o0KEDRx11VLHjL1q0iBEjRlCnTh0yMzO57777qFevHk8//TRXXXUVmzdvZufOnfzmN7+hS5cu/POf/+TSSy9lzz33pH///mWOU0QSKHi6/vUxeuq+GrIa+pPwai83N9cLfvtd4H//+x+HHHJIymVU5WsmX3zxRZYtW1bkgTqRqlLafUOiyczmuntuuuOIGp3RV2NndG9VZe+PLnjYTkREokX36EVERCJMiV5ERCTClOhFREQiTIleREQkwpToRUREIkyJvhZRM7WBymqmtjo3f7tp0ybuvffeCitv+fLl/Otf/yr19wYNGsTTTz9dYXGISMmU6GuR2GZqgSprprYiTZs2jSZNmlRomVVp165dJY9UCYpL9GWJqayJXkSqnhJ9dbZwMtzRFUY3Cf5XQJOPaqY2eTO1W7ZsoW/fvvTo0YOsrCyef/55IEhqhxxyCJdffjldunShX79+5Ofnp1zujBkzOO6447jwwgvJyspi165djBgxgsMPP5zs7GweeOCBwnH/+te/kpWVRbdu3QoPyObPn0+vXr3Izs7mzDPPZOPGjUBwpeO6666jZ8+edOrUibfffhuAxYsX07NnT3JycsjOzubTTz9l5MiRfPbZZ+Tk5DBixIjdYoq/GnHbbbcxevRoAJYuXcoJJ5xAt27d6NGjB5999hkjR47k7bffJicnhzvuuCPpPLk7w4YN49BDD2XAgAGsXbs24TISkUrk7vqrhL/DDjvM43300Ue79UtqwST3mw9wv3HvH/9uPiDoX04vv/yyA/7qq6+mND7gL7zwgru7jxgxwm+66SZ3dz/11FN9/Pjx7u7+8MMP++mnn+7u7gMHDvQBAwb4zp07C7vPO+88/+GHH3zKlCneqFEjX7hwoe/atct79OjhH3zwgbu7b9iwwd3dd+7c6X369PEFCxa4u3ufPn189uzZ7u7etm1bX7dunT/99NN+2WWXFca4adMm//777713796+du1ad3efOHGiX3LJJe7unpWV5TNmzHB392uuuca7dOmy23zu2LHDN2/e7O7u69at84MOOsh/+OEH//zzzz0jI6MwznPOOccnTJiQcrlvvvmm77nnnr5s2TJ3d3/ggQcKl+H27dv9sMMO82XLlvm0adO8d+/evnXr1iLLI3Yaf/zjH3348OGFy+W3v/2tu7tPnTrV+/bt6+7uw4YN88cff9zd3b/77jvftm2bf/7550Vii48pfvjYsWP9xhtvdHf3nj17+rPPPuvu7vn5+b5161Z/8803fcCAAYXjJ5unZ555xk844QTfuXOnr1y50hs3buxPPfXUbsuoVPuGRBYwx6tB/R21P53RV1evjwnac45VQe07q5naxM3Uuju///3vyc7O5oQTTmDlypWFVy/at29PTk5OkWVQmuZve/bsSfv27QF49dVXeeyxx8jJyeGII45gw4YNfPrpp0yfPp1LLrmEPffcE4B99913t2kMHDiQt956q7Dcs846a7f10rt3b2655Rb+8pe/8MUXX9CgQeKGkGJjSubbb79l5cqVnHnmmQDUr1+/ML5Yyebprbfe4oILLiAjI4OWLVty/PHHFzs9Eal4egVudZWsHedytu+sZmqTe+KJJ1i3bh1z584lMzOTdu3aFcYQG3NGRgb5+fm4e8rN38YuD3fn73//+26N67z88sulbk63IK7Y9XLhhRdyxBFHMHXqVPr3789DDz1Ehw4dio2pbt26/PDDD4XdBfMdnGSVLNk8TZs2TU0Ei6SZzuirq2TtOJejfWd3NVNbEGsimzdvZv/99yczM5M333yzxF8jlLX52/79+3PfffexY8cOAD755BO2bt1Kv379eOSRR9i2bRsAX3/9NY0bN2afffYpvP8+YcKEwrP7ZJYtW0aHDh246qqr+NnPfsbChQtp1KgR3377bdLvHHDAAaxdu5YNGzbw3Xff8eKLLwKw995707p1a6ZMmQLAd999x7Zt23YrL9k8HXPMMUycOJFdu3axevVq3nzzzZSWkYhUHJ3RV1d9R8G/ryp6+b6c7Turmdrim6m96KKLOO2008jNzSUnJyelA5+yNH972WWXsXz5cnr06IG706xZM6ZMmcJJJ53E/Pnzyc3NpV69epxyyinccsstPProowwZMoRt27bRoUOHEpfzpEmTePzxx8nMzKR58+aMGjWKfffdl6OOOoquXbty8sknM2DAgCLfyczMZNSoURxxxBG0b9++yLxPmDCBX/3qV4waNYrMzEyeeuopsrOzqVu3Lt26dWPQoEEMHz484TydeeaZvPHGG2RlZdGpU6cSD1JEpOKpmdpKUhHN1LJwcpW176xmaiWd1EytgJqprSw6o6/Oss+ttMQeT83UiohEk+7Ri4iIRJgSvYiISIQp0YuIiESYEr2IiEiE1fpEb2aPmNlaM0v4mjgL3G1mS81soZn1qOoYRUREyqrWJ3pgPHBSMcNPBjqGf4OB+6ogpkrzpz/9iS5dupCdnU1OTg7//e9/geC33cW9crY4ldk866hRo5g+fXqZvlueJm1rS3OqM2bM4J133kl3GCJSiWr9z+vc/S0za1fMKKcDj4UNLrxnZk3MrIW7r66aCCvOu+++y4svvsi8efPYY489WL9+Pd9//z0ADz30UJqj292uXbsYM6bs7/afNm1aBUYTTTNmzKBhw4YceeSR6Q5FRCqJzuhL1gpYEdOdF/bbjZkNNrM5ZjZn3bp15Z7w1GVT6fd0P7Ifzabf0/2YumxqucpbvXo1TZs2LXw/etOmTWnZsiUQNHla8IKfZM3SfvbZZ/Tq1YvDDz+cUaNG0bBhw92mUVwTrAWWL1/OwQcfzMCBA8nOzubss88ufO1ru3btGDNmDEcffTRPPfVUkTPrdu3aceONNxY2I/vxxx8DQfOyl1xyCVlZWWRnZ/PMM88Ujr9+/fpipzdmzBgOP/xwunbtyuDBg0t8O2CiJlvdnREjRtC1a1eysrIKm8ydMWMGffr04dxzz6VTp06MHDmSJ554gp49e5KVlcVnn30GBFcPhgwZwk9/+lM6depU+PrZ7du3F85X9+7dC18fO378eM466yxOOukkOnbsyLXXXlsY36uvvkrv3r3p0aMH55xzDlu2bEm67JYvX87999/PHXfcQU5OTuFrdkUkWpToS5aoRY6E2cDdx7l7rrvnNmvWrFwTnbpsKqPfGc3qratxnNVbVzP6ndHlSvb9+vVjxYoVdOrUiSuuuIKZM2cmHG/r1q306tWLBQsWcMwxx/Dggw8CMHz4cIYPH87s2bMLDxDiPfzwwzRu3JjZs2cze/ZsHnzwQT7//PPdxluyZAmDBw9m4cKF7L333tx7772Fw+rXr8+sWbM4//zzd/te06ZNmTdvHkOHDuW2224D4KabbqJx48YsWrSIhQsXJmwhLdn0hg0bxuzZs/nwww/Jz88vTLLJXHTRRVx55ZUsWLCAd955hxYtWvDss88yf/58FixYwPTp0xkxYgSrVwcXfBYsWMBdd93FokWLmDBhAp988gnvv/8+l112GX//+98Ly12+fDkzZ85k6tSpDBkyhO3btxe2b79o0SKefPJJBg4cWNjYzPz585k0aRKLFi1i0qRJrFixgvXr13PzzTczffp05s2bR25uLrfffnvSZdeuXTuGDBnC1Vdfzfz58/npT39a7LyLSM2kRF+yPKBNTHdrYFVlT/SueXexfVfR1tu279rOXfPuKnOZDRs2ZO7cuYwbN45mzZpx3nnnMX78+N3GK65Z2nPOOQegsHnaeMmaK43Xpk2bwvfZX3zxxUWauD3vvPOSzkOiZlmnT5/OlVdeWTjOPvvsk/L03nzzTY444giysrJ44403WLx4cdJpJ2uyddasWYVNsR5wwAH06dOH2bNnA3D44YfTokUL9thjDw466CD69esHBM3sFsQPcO6551KnTh06duxIhw4d+Pjjj5k1a1Zh07cHH3wwbdu25ZNPPgGgb9++NG7cmPr163PooYfyxRdf8N577/HRRx9x1FFHkZOTw6OPPlqkYZ5Ey05Eoq/W36NPwQvAMDObCBwBbK6K+/Nrtq4pVf9UZWRkcOyxx3LssceSlZXFo48+yqBBg4qMk2qztIkka640XnzTpcU1cRsrUbOsqTQXm2h627dv54orrmDOnDm0adOG0aNHF9s0brLL+sVd7o9vkje2ud7Y5ZoovlTLLVgW7s6JJ57Ik08+Wex3SrtORaRmq/Vn9Gb2JPAu0NnM8szsl2Y2xMyGhKNMA5YBS4EHgSuqIq7mezUvVf9ULFmypMjZ9fz582nbtm3K3+/Vq1fh/e+C5mnjJWuuNN6XX35Z2Jzsk08+Wa4mbvv168c//vGPwu6NGzemNL2CpN60aVO2bNlS4lP2yZpsPeaYY5g0aRK7du1i3bp1vPXWW/Ts2bNU8/DUU0/xww8/8Nlnn7Fs2TI6d+7MMcccU9j07SeffMKXX35J586dk5bRq1cv/vOf/7B06VIAtm3bVngFIJmSmq8VkZqv1id6d7/A3Vu4e6a7t3b3h939fne/Pxzu7n6lux/k7lnuPqekMivC8B7DqZ9Rv0i/+hn1Gd5jeJnL3LJlCwMHDuTQQw8lOzubjz76iNGjR6f8/TvvvJPbb7+dnj17snr1aho3brzbOJdddhmHHnooPXr0oGvXrvzqV79KePZ4yCGH8Oijj5Kdnc3XX3/N0KFDyzxff/jDH9i4cSNdu3alW7duCds8TzS9Jk2acPnll5OVlcUZZ5zB4YcfXuK0JkyYwN133012djZHHnkka9as4cwzzyQ7O5tu3bpx/PHH89e//pXmzUt3QNa5c2f69OnDySefzP3330/9+vW54oor2LVrF1lZWYW3WWLP5OM1a9aM8ePHc8EFF5CdnU2vXr0KH1hM5rTTTuO5557Tw3giEaZmaitJRTRTO3XZVO6adxdrtq6h+V7NGd5jOAM6DCj5i5Vk27ZtNGjQADNj4sSJPPnkkzz//POlLmf58uWceuqpfPhhwncUVbiqnl5pDRo0iFNPPZWzzz473aGkjZqpFVAztZVF9+irsQEdBqQ1scebO3cuw4YNw91p0qQJjzzySLpDEhGREuiMvpJUxBm9SG2hfUNAZ/SVpdbfo69qOrASKUr7hEjlUqKvQvXr12fDhg2q2ERC7s6GDRuoX79+ySOLSJnoHn0Vat26NXl5eVTE63FFoqJ+/fq0bt063WGIRJYSfRXKzMykffv26Q5DRERqEV26FxERiTAlehERkQhTohcREYkwJXoREZEIU6IXERGJMCV6EZEEpi6bSr+n+5H9aDb9nu7H1GVT0x2SSJno53UiInGmLpvK6HdGs31X0JTx6q2rGf3OaIBq1f6ESCp0Ri8iEueueXcVJvkC23dt5655d6UpIpGyU6IXEYmzZuuaUvUXqc6U6EVE4jTfq3mp+otUZ0r0IiJxhvcYTv2Mog3t1M+oz/Aew9MUkUjZ6WE8EZE4BQ/c3TXvLtZsXUPzvZozvMdwPYgnNZISvYhIAgM6DFBil0jQpXsREZEIU6IXERGJMCV6ERGRCFOiFxERiTAlehERkQhTohcREYmwWp/ozewkM1tiZkvNbGSC4cea2WYzmx/+jUpHnCIiImVRq39Hb2YZwD3AiUAeMNvMXnD3j+JGfdvdT63yAEVERMqptp/R9wSWuvsyd/8emAicnuaYREREKkxtT/StgBUx3Xlhv3i9zWyBmb1kZl2qJjQREZHyq9WX7gFL0M/juucBbd19i5mdAkwBOiYszGwwMBjgwAMPrMAwRUREyqa2n9HnAW1iulsDq2JHcPdv3H1L+HkakGlmTRMV5u7j3D3X3XObNWtWWTGLiIikrLYn+tlARzNrb2b1gPOBF2JHMLPmZmbh554Ey2xDlUcqIiJSBrX60r277zSzYcArQAbwiLsvNrMh4fD7gbOBoWa2E8gHznf3+Mv7IiIi1ZIpZ1WO3NxcnzNnTrrDEBGpMcxsrrvnpjuOqKntl+5FREQiTYleREQkwpToRSR9Fk6GO7rC6CbB/4WT0x2RSOTU6ofxRCSNFk6Gf18FO/KD7s0rgm6A7HPTF5dIxOiMXkTS4/UxPyb5Ajvyg/4iUmGU6EUkPTbnla6/iJSJEr2IpEfj1qXrLyJlokQvIunRdxRkNijaL7NB0F9EKowexhOR9Ch44O71McHl+satgySf4EG8KR+sZOwrS1i1KZ+WTRowon9nzuieqKFJEYmnRC8i6ZN9bolP2E/5YCXXP7uI/B27AFi5KZ/rn10EoGQvkgJduheRam3sK0sKk3yB/B27GPvKkjRFJFKzKNGLSLW2alN+qfqLSFFK9CJSrbVs0qBU/UWkKCV6EanWRvTvTIPMjCL9GmRmMKJ/5zRFJFKz6GE8EanWCh6401P3ImWjRC8i1d4Z3VspsYuUkS7di4iIRJgSvYiISIQp0YuIiESYEr2IiEiEKdGLiIhEmBK9iIhIhCnRi4iIRFiNTvRmdmK6YxAREanOanSiBx5OdwAiIiLVWbV/M56ZvZBsELBfVcYiIiJS01T7RA/8FLgY2BLX34CeVR+OiIhIzVETEv17wDZ3nxk/wMyWlLdwMzsJuAvIAB5y91vjhls4/BRgGzDI3eeVd7oiIiJVoSYk+sHuviLJsBvKU7CZZQD3ACcCecBsM3vB3T+KGe1koGP4dwRwX/hfRESk2qsJD+PNNLNrzazwoMTMDjCzx4Hby1l2T2Cpuy9z9++BicDpceOcDjzmgfeAJmbWopzTFRERqRI1IdEfBhwEfGBmx5vZcOB94F3Kf2bdCoi9WpAX9ivtOACY2WAzm2Nmc9atW1fO0ERERMqv2l+6d/eNwK/CBD8dWAX0cve8CijeEk2yDOMEPd3HAeMAcnNzE44jIiJSlar9Gb2ZNTGzB4BLgJOAp4GXzOz4Cig+D2gT092a4ECitOOIiIhUS9U+0QPzgE+BXHd/1d1/A/wcuNnMnixn2bOBjmbW3szqAecD8b/bfwH4hQV6AZvdfXU5pysiIlIlqv2le+CY+Mv07j4fONLMLi9Pwe6+08yGAa8Q/LzuEXdfbGZDwuH3A9MIflq3lODndZeUZ5oiIiJVydx1K7ky5Obm+pw5c9IdhohIjWFmc909N91xRE1NuHQvIiIiZaRELyIiEmFK9CIiIhGmRC8iIhJhSvQiIiIRpkQvIiISYUr0IiIiEaZELyIiEmFK9CIiIhGmRC8iIhJhSvQiIiIRpkQvIiISYUr0IiIiEaZELyIiEmFK9CIiIhGmRC8iIhJhSvQiIiIRpkQvIiISYUr0IiIiEaZELyIiEmF10x2ASHU15YOVjH1lCas25dOySQNG9O/MGd1bpTssEZFSUaIXSWDKByu5/tlF5O/YBcDKTflc/+wiACV7EalRlOhFEhj7ypLCJP+zOrO4tu5kWtp61j7fDDJugexz0xyhiEhqlOhFEli1KR8IkvytmQ+xp30PQHPWwb+vCkZSsheRGkAP44kk0LJJAwCurTu5MMkX2pEPr49JQ1QiIqWnRC+SwIj+nWmQmUFLW594hM15VRuQiEgZ6dK9SAIFD9ytfb5ZcLk+XuPWVRyRiEjZ1NozejPb18xeM7NPw//7JBlvuZktMrP5ZjanquOU9Dmjeyuan3ULZDYoOiCzAfQdlZ6gRERKqdYmemAk8Lq7dwReD7uTOc7dc9w9t2pCk2oj+1w47W5o3Aaw4P9pd+tBPBGpMWrzpfvTgWPDz48CM4Dr0hWMVGPZ5yqxi0iNVZvP6A9w99UA4f/9k4znwKtmNtfMBhdXoJkNNrM5ZjZn3boE93VFRESqWKTP6M1sOtA8waAbSlHMUe6+ysz2B14zs4/d/a1EI7r7OGAcQG5urpc6YBERkQoW6UTv7ickG2ZmX5lZC3dfbWYtgLVJylgV/l9rZs8BPYGEiV5ERKS6qc2X7l8ABoafBwLPx49gZnuZWaOCz0A/4MMqi1BERKScanOivxU40cw+BU4MuzGzlmY2LRznAGCWmS0A3gemuvvLaYlWRESkDCJ96b447r4B6Jug/yrglPDzMqBbFYcmIiJSYWrzGb2IiEjkKdGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YuIiESYEr2IiEiEKdGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YuIiESYEr2IiEiEKdGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YuIiESYEr2IiEiEKdGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YuIiESYEr2IiEiEKdGLiIhEmBK9iIhIhNXaRG9m55jZYjP7wcxyixnvJDNbYmZLzWxkVcYoIiJSXrU20QMfAmcBbyUbwcwygHuAk4FDgQvM7NCqCU9ERKT86qY7gHRx9/8BmFlxo/UElrr7snDcicDpwEeVHqCIiEgFqM1n9KloBayI6c4L+yVkZoPNbI6ZzVm3bl2lByciIlKSSJ/Rm9l0oHmCQTe4+/OpFJGgnycb2d3HAeMAcnNzk44nIiJSVSKd6N39hHIWkQe0ieluDawqZ5kiIiJVRpfuizcb6Ghm7c2sHnA+8EKaYxIREUlZrU30ZnammeUBvYGpZvZK2L+lmU0DcPedwDDgFeB/wGR3X5yumEVEREor0pfui+PuzwHPJei/CjglpnsaMK0KQxMREakwtfaMXkREpDZQohcREYkwJXoREZEIU6IXERGJMCV6ERGRCFOiFxERiTAlehERkQhTohcREYkwJXoREZEIU6IXERGJMCV6ERGRCFOiFxERibBa26hNdTTlg5WMfWUJqzbl07JJA0b078wZ3VulOywREanBlOiriSkfrOT6ZxeRv2MXACs35XP9s4sAlOxFRKTMlOiribGvLClM8j+rM4tr606mpa1n7fPNIOMWyD43zRGKiEhNpERfTazalA8ESf7WzIfY074HoDnr4N9XBSMp2YuISCnpYbxqomWTBgBcW3dyYZIvtCMfXh+ThqhERKSmU6KvJkb070yDzAxa2vrEI2zOq9qAREQkEnTpvpooeOBu7fPNgsv18Rq3ruKIREQkCnRGX42c0b0Vzc+6BTIbFB2Q2QD6jkpPUCIiUqMp0Vc32efCaXdD4zaABf9Pu1sP4omISJno0n11lH2uEruIiFQIndGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YuIiESYuXu6Y4gkM1sHfJHuOCpYUyDJq/siIcrzF+V5A81fTRY7b23dvVk6g4kiJXpJmZnNcffcdMdRWaI8f1GeN9D81WRRnrfqQpfuRUREIkyJXkREJMKU6KU0xqU7gEoW5fmL8ryB5q8mi/K8VQu6Ry8iIhJhOqMXERGJMCV6ERGRCFOil6TM7BwzW2xmP5hZ0p+/mNlJZrbEzJaa2ciqjLE8zGxfM3vNzD4N/++TZLzlZrbIzOab2ZyqjrM0SloXFrg7HL7QzHqkI86ySmH+jjWzzeG6mm9mo9IRZ1mY2SNmttbMPkwyvKavu5Lmr8auu+pOiV6K8yFwFvBWshHMLAO4BzgZOBS4wMwOrZrwym0k8Lq7dwReD7uTOc7dc6rz731TXBcnAx3Dv8HAfVUaZDmUYlt7O1xXOe4+pkqDLJ/xwEnFDK+x6y40nuLnD2ruuqvWlOglKXf/n7svKWG0nsBSd1/m7t8DE4HTKz+6CnE68Gj4+VHgjPSFUiFSWRenA4954D2giZm1qOpAy6gmb2slcve3gK+LGaUmr7tU5k8qiRK9lFcrYEVMd17YryY4wN1XA4T/908yngOvmtlcMxtcZdGVXirroiavr1Rj721mC8zsJTPrUjWhVYmavO5SFdV1l1Z10x2ApJeZTQeaJxh0g7s/n0oRCfpVm99sFjd/pSjmKHdfZWb7A6+Z2cfh2Ul1k8q6qNbrqwSpxD6P4H3pW8zsFGAKwaXuKKjJ6y4VUV53aaVEX8u5+wnlLCIPaBPT3RpYVc4yK0xx82dmX5lZC3dfHV4CXZukjFXh/7Vm9hzBJeTqmOhTWRfVen2VoMTY3f2bmM/TzOxeM2vq7lFoEKYmr7sSRXzdpZUu3Ut5zQY6mll7M6sHnA+8kOaYUvUCMDD8PBDY7QqGme1lZo0KPgP9CB5SrI5SWRcvAL8In+DuBWwuuH1RA5Q4f2bW3Mws/NyToI7bUOWRVo6avO5KFPF1l1Y6o5ekzOxM4O9AM2Cqmc139/5m1hJ4yN1PcfedZjYMeAXIAB5x98VpDLs0bgUmm9kvgS+BcwBi5w84AHgurH/qAv9y95fTFG+xkq0LMxsSDr8fmAacAiwFtgGXpCve0kpx/s4GhprZTiAfON9ryOs/zexJ4FigqZnlATcCmVDz1x2kNH81dt1Vd3oFroiISITp0r2IiEiEKdGLiIhEmBK9iIhIhCnRi4iIRJgSvYiISIQp0YtElJm1MbPPzWzfsHufsLutmQ20oNW+T81sYElliUjNpZ/XiUSYmV0L/MTdB5vZA8By4AFgDpBL8ArVucBh7r4xbYGKSKXRGb1ItN0B9DKz3wBHA38D+gOvufvXYXJ/jZKbDxWRGkpvxhOJMHffYWYjgJeBfu7+vZnVhlbQRCSkM3qR6DsZWA10Dbuj3gqaiMRQoheJMDPLAU4EegFXh630RboVNBEpSg/jiURU2BLYO8Aod3/NzH5NkPB/TfAAXo9w1HkED+N9nZ5IRaQy6YxeJLouB75099fC7nuBg4Es4CaCZl9nA2OU5EWiS2f0IiIiEaYzehERkQhTohcREYkwJXoREZEIU6IXERGJMCV6ERGRCFOiFxERiTAlehERkQj7/yANjbRNWPkFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Plot X_norm, X_norm but reconstructed and the single principal component. \n",
    "plt.scatter(X_norm[:,0], X_norm[:,1], label=\"X, normalised\")\n",
    "plt.scatter(X_norm_reconstr[:,0], X_norm_reconstr[:,1], label=\"X, normalised and reconstructed\")\n",
    "plt.scatter(components[0,0], components[0,1], label=\"Single principal component\")\n",
    "\n",
    "plt.title(\"True and reconstructed values of a dataset X with the single principal component\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VRmTKPon54C"
   },
   "source": [
    "## Score and reconstruct _new_ data\n",
    "\n",
    "We will now represent new data in terms of $k$ principal components. For that, we first need to normalize the \"new\" data's feature values using the \"old\" `orig_center` and `orig_std`, so that everything is comparable.\n",
    "\n",
    "We get the new $\\mathbf{V}^{\\mathrm{T}}$ with $\\mathbf{X} (\\mathbf{U}\\mathbf{\\Sigma})^{-1}=\\mathbf{X} (\\mathbf{U}\\mathbf{\\Sigma})^{\\mathrm{T}}$. It could be useful to try to figure out why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqDhE13Sh0Dy"
   },
   "source": [
    "### Exercise 3: implement `score_new_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VqszvTPQn54D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.4]\n",
      " [1.  2. ]\n",
      " [2.  3.2]\n",
      " [3.  5.3]]\n",
      "[[0.458 1.058]\n",
      " [2.53  4.372]]\n"
     ]
    }
   ],
   "source": [
    "def score_new_data(new_X, orig_center, orig_std, components):\n",
    "    \"\"\"`new_X` is a numpy.ndarray. Rows represent instances. Columns represent feature values.\n",
    "    First, create a modified copy of `new_X` as if normalizing it using `orig_center` and \n",
    "    `orig_std`. These params refer to feature means and standard deviations respectively. \n",
    "    Output is a representation of this normalized `new_X` in terms of `components`, i.e., a score \n",
    "    matrix.\"\"\"\n",
    "    #Normalise new X \n",
    "    new_normalised_X = (new_X - orig_center)/orig_std\n",
    "    #Obtain USigma\n",
    "    \n",
    "    score = new_normalised_X @ np.matrix.transpose(components)\n",
    "    return score\n",
    "    \n",
    "\n",
    "print(X.round(3))\n",
    "new_X = np.array([[0.5, 0.99],\n",
    "                  [2.5, 4.42]])\n",
    "# If you don't have `orig_center` and `orig_std`, you can come up with some fake values.\n",
    "# (You can find the dimensions of these variables in their test function.)\n",
    "new_score = score_new_data(new_X, orig_center, orig_std, components)\n",
    "new_X_norm_reconstr = new_score @ components\n",
    "print(uncenter_and_unscale(new_X_norm_reconstr, orig_center, orig_std).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N-WsDaYeymPg"
   },
   "outputs": [],
   "source": [
    "def test_score_new_data():\n",
    "    for k in [1,2,3]:\n",
    "\n",
    "        X = sk_scale(np.array([[0.0, 0.4, -1, 1],\n",
    "                               [1.0, 1.6, -2, 2],\n",
    "                               [2.0, 3.4, -3, 3.5],\n",
    "                               [3.0, 4.6, -4, 5]]))\n",
    "        new_X = sk_scale(np.array([[0.5, 0.99, 1, -2],\n",
    "                                   [2.5, 3.99, -42, -9]]))\n",
    "        sk_pca = PCA(n_components=k)\n",
    "        score = sk_pca.fit_transform(X)\n",
    "        components = sk_pca.components_\n",
    "        new_score = score_new_data(new_X, [1.42, 2.42, 4, 4], [1.11, 1.66, 2, 3], components)\n",
    "        new_X_reconstr = new_score @ components\n",
    "        if k == 1:\n",
    "            assert helpful_eq(new_X_reconstr, \n",
    "                              np.array([[-0.93533774, -0.93443902,  0.93533774, -0.93414063],\n",
    "                                        [-0.09948932, -0.09939373,  0.09948932, -0.09936199]]))\n",
    "        elif k == 2:\n",
    "            assert helpful_eq(new_X_reconstr, \n",
    "                              np.array([[-0.57078589, -1.07598312,  0.57078589, -1.52258937],\n",
    "                                        [ 0.98203221, -0.51931478, -0.98203221, -1.84512183]]))\n",
    "        elif k == 3:\n",
    "            assert helpful_eq(new_X_reconstr, \n",
    "                              np.array([[-0.34009009, -2.06024096,  0.34009009, -1.        ],\n",
    "                                        [ 1.06081081, -0.85542169, -1.06081081, -1.66666667]]))\n",
    "\n",
    "\n",
    "test_score_new_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_9J_1BOwSn6"
   },
   "source": [
    "## Wrap our work in a `pca` function\n",
    "\n",
    "This is fairly self-explanatory. You could create an object to keep track of so many variables, but you have seen that trick before; a dictionary works too. If you do not break anything that is already here, you could store more relatively small variables in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "error",
     "timestamp": 1618830473722,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "",
      "userId": "13006621849040554927"
     },
     "user_tz": -120
    },
    "id": "hAquONvZwSn6",
    "outputId": "e35040a5-aba4-4687-c672-b79a7171c075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_center\n",
      "[1.5   2.725]\n",
      "\n",
      "orig_std\n",
      "[1.118 1.788]\n",
      "\n",
      "components\n",
      "[[0.5292 0.8485]]\n",
      "\n",
      "score\n",
      "[[-2.7666]\n",
      " [-0.8798]\n",
      " [ 0.6676]\n",
      " [ 2.9787]]\n",
      "\n",
      "R_squared\n",
      "[0.9971 0.0029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pca(X, k):\n",
    "    \"\"\"All components are explained above. If you did not complete `center_and_scale` or \n",
    "    `svd_to_components_and_score`, you can fit in the scikit-learn alternatives exemplified \n",
    "    (in the tests) above.\"\"\"\n",
    "    X_norm, orig_center, orig_std = center_and_scale(X)\n",
    "    U, Sigma_elements, V_transpose = np.linalg.svd(X_norm, full_matrices=False)\n",
    "    S_squared_sum = sum(S_i ** 2 for S_i in Sigma_elements)\n",
    "    R_squared = [S_i ** 2 / S_squared_sum for S_i in Sigma_elements]\n",
    "    #components, score = svd_to_components_and_score(U, Sigma_elements, V_transpose, k)\n",
    "    sk_pca = PCA(n_components=k)\n",
    "    sk_score = sk_pca.fit_transform(X)\n",
    "    sk_components = sk_pca.components_\n",
    "    components, score = sk_components, sk_score \n",
    "    return {\n",
    "        'orig_center': orig_center,\n",
    "        'orig_std': orig_std,\n",
    "        'components': components,\n",
    "        'score': score,\n",
    "        'R_squared': np.array(R_squared)\n",
    "    }\n",
    "\n",
    "\n",
    "pca_dict = pca(X, k)\n",
    "for key in pca_dict.keys():\n",
    "    print(key)\n",
    "    print(pca_dict[key].round(4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du6bqtJbwSn7"
   },
   "source": [
    "# Big(ger) data\n",
    "\n",
    "We will now use PCA in the pre-processing of a more realistic dataset, and test whether it helped in improving prediction accuracy and/or reducing model fitting and other computational time. We will use the support vector machine classifier of that you have seen before. The specific model is not important; that PCA or other pre-processing can help is. (And, to be fair, PCA and other pre-processing techniques can also have more costs than benefits when using other models.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nia3F-UCIAxX"
   },
   "source": [
    "## Load/create more complicated dataset\n",
    "\n",
    "There is a little more information about the dataset `load_breast_cancer` loads on https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) and https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset. We modify the dataset to consist of more samples through repeats, but add a decent amount of noise (independently sampled from a normal distribution with mean zero and a quarter of that feature's own standard deviation). We also add two categorical features in the columns of `X` that are in `non_num_idx`. \n",
    "\n",
    "So the dataset does not represent what it's based on very closely anymore. But to give a little more information, in `X, y = load_breast_cancer(return_X_y=True)` set,  `X` has 569 instances of 30 numeric features but 10 categories of attributes:\n",
    "\n",
    "0. radius (mean of distances from center to points on the perimeter)\n",
    "1. texture (standard deviation of gray-scale values)\n",
    "2. perimeter\n",
    "3. area\n",
    "4. smoothness (local variation in radius lengths)\n",
    "5. compactness (perimeter^2 / area - 1.0)\n",
    "6. concavity (severity of concave portions of the contour)\n",
    "7. concave points (number of concave portions of the contour)\n",
    "8. symmetry\n",
    "9. fractal dimension (coastline approximation - 1)\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) (sample) from a tumor. They describe characteristics of the cell nuclei present in the image. The mean, standard error, and mean of the three largest values of these characteristics were computed for each of the 569 images/instances, resulting in 30 features. For instance, field 0 is mean radius, field 10 is radius standard error, field 20 is the mean of the three largest radii.\n",
    "\n",
    "The `y` contains a 0 for malignant samples, and a 1 for benign ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cCuVeoBDn54K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5690, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_big_X_y():\n",
    "    \"\"\"It's not necessary to understand completely what is happening, but notice that \n",
    "    the columns whose indices are in `non_num_idx` represent categorical features.\"\"\"\n",
    "    X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "    # Add some instances\n",
    "    X = np.repeat(X, 10, axis=0)\n",
    "    y = np.repeat(y, 10)\n",
    "\n",
    "    X, y = sk_shuffle(X, y, random_state=11)\n",
    "\n",
    "    # Add two categorical features (that have a 60% prob of being right)\n",
    "    np.random.seed(42)\n",
    "    X = np.hstack((np.random.binomial(1, 0.4 + 0.2 * y).reshape(-1, 1),\n",
    "                   np.random.binomial(1, 0.4 + 0.2 * y).reshape(-1, 1),\n",
    "                   X))\n",
    "    non_num_idx = [0, 1]\n",
    "    \n",
    "    # Add noise to numerical features\n",
    "    num = [i for i in range(X.shape[1]) if i not in non_num_idx]\n",
    "    X[:, num] += np.random.normal(0, 0.25 *\n",
    "                                  X[:, num].std(axis=0), X[:, num].shape)\n",
    "\n",
    "    # Replace some % of numerical values with np.nan\n",
    "    X_num_flat = X[:, num].flatten()\n",
    "    n_to_remove = int(len(X_num_flat) * .1)\n",
    "    to_remove = np.random.permutation(range(len(X_num_flat)))[:n_to_remove]\n",
    "    X_num_flat[to_remove] = np.nan\n",
    "    X[:, num] = X_num_flat.reshape(X[:, num].shape)\n",
    "\n",
    "    return X, y, non_num_idx\n",
    "\n",
    "\n",
    "# big_... name to not confuse with our previous simple `X`.\n",
    "big_X, big_y, non_num_idx = create_big_X_y()\n",
    "big_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2g5edAcMQO8"
   },
   "source": [
    "## Already split off a test set\n",
    "\n",
    "We will perform repeated cross-validation later on, but while we create and test our functions it is already useful to have a separation of training and test set in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "v7vSOUxQMRNe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.         15.06097903 ...  0.15495723  0.28133099\n",
      "   0.08943424]\n",
      " [ 0.          0.         21.84106715 ...  0.22074183  0.23638334\n",
      "   0.07476276]\n",
      " [ 0.          1.         13.38384299 ...  0.17935782  0.32982295\n",
      "          nan]\n",
      " ...\n",
      " [ 0.          0.         19.38073173 ...  0.24628595  0.35549601\n",
      "   0.07880792]\n",
      " [ 1.          0.         15.35308404 ...  0.13026943  0.2673978\n",
      "   0.07985852]\n",
      " [ 0.          1.         15.77904129 ...         nan  0.32416498\n",
      "   0.08275628]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = NFolds(big_X, big_y, seed=5).get_fold(0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKgW9ZjrskoK"
   },
   "source": [
    "## Explore the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bSTvz5nOskoK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.49133427e-01 2.49269861e-01 1.30239321e+01 1.89255738e+01\n",
      " 6.18336675e+02 1.29040402e+05 2.12158331e-04 2.94041160e-03\n",
      " 6.63346011e-03 1.58491041e-03 7.95991391e-04 5.25961687e-05\n",
      " 7.86259443e-02 3.22935870e-01 4.29950538e+00 2.07958994e+03\n",
      " 9.38669449e-06 3.40239534e-04 9.54591729e-04 4.04140203e-05\n",
      " 7.29441422e-05 7.60999841e-06 2.38950708e+01 4.02706724e+01\n",
      " 1.17861009e+03 3.32851543e+05 5.58867645e-04 2.58921362e-02\n",
      " 4.61476986e-02 4.49718848e-03 4.12840608e-03 3.47023685e-04]\n"
     ]
    }
   ],
   "source": [
    "X_nanvar = np.nanvar(X_train,axis=0)\n",
    "print(X_nanvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS25qzlWnwrk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 4: can you come up with a feature transformation (for one or more column(s) of `X`) that would make the principal components express more of the data's variance?\n",
    "\n",
    "There are some columns with a very low variance (value smaller than 0.0001). We could scale those features so that they weigh less than the features with a high variance, by for example scaling and centering them different, so that the PCA express more of the data's variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EL-wAlZ2IEOd"
   },
   "source": [
    "## Replace missing _numerical_ values\n",
    "\n",
    "We will use a simple mean imputation to replace the missing values. Remember that we do not want to use any information from our test set before our final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh0nIGEzyt9R"
   },
   "source": [
    "### Exercise 4: implement `mean_impute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.         15.06097903 ...  0.15495723  0.28133099\n",
      "   0.08943424]\n",
      " [ 0.          0.         21.84106715 ...  0.22074183  0.23638334\n",
      "   0.07476276]\n",
      " [ 0.          1.         13.38384299 ...  0.17935782  0.32982295\n",
      "          nan]\n",
      " ...\n",
      " [ 0.          0.         19.38073173 ...  0.24628595  0.35549601\n",
      "   0.07880792]\n",
      " [ 1.          0.         15.35308404 ...  0.13026943  0.2673978\n",
      "   0.07985852]\n",
      " [ 0.          1.         15.77904129 ...         nan  0.32416498\n",
      "   0.08275628]]\n"
     ]
    }
   ],
   "source": [
    "def mean_impute(X_train, X_test):\n",
    "    \"\"\"We assume numpy.ndarrays `X_train` and `X_test` only have numpy.nan as missing values in \n",
    "    their numerical features (columns). The output should be modified copies of `X_train` and \n",
    "    `X_test` where the missing values are replaced by the mean of the column of `X_train` in which \n",
    "    the value was missing. (The test might enlighten you.)\"\"\"\n",
    "    #Get mean values of X_train\n",
    "    X_train_nanmean = np.nanmean(X_train, axis=0)\n",
    "    \n",
    "    for i in range(0, X_train.shape[1]):\n",
    "        X_train[:,i] = np.nan_to_num(X_train[:,i], nan=X_train_nanmean[i])\n",
    "        X_test[:,i] = np.nan_to_num(X_test[:,i], nan=X_train_nanmean[i])\n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "#X_train, X_test = mean_impute(X_train, X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6SurEQy2ymPk"
   },
   "outputs": [],
   "source": [
    "def test_mean_impute():\n",
    "    X_train = np.array([[1, 2, np.nan],\n",
    "                        [3, 4, 5]])\n",
    "    X_test = np.array([[np.nan, 0, 3]])\n",
    "    X_train, X_test = mean_impute(X_train, X_test)\n",
    "    assert helpful_eq(X_train, [[1., 2., 5.], [3., 4., 5.]])\n",
    "    assert helpful_eq(X_test, [[2., 0., 3.]])\n",
    "    big_X, big_y, non_num_idx = create_big_X_y()\n",
    "    X_train, X_test, _, _ = NFolds(big_X, big_y, seed=5).get_fold(0)\n",
    "    X_train, X_test = mean_impute(X_train, X_test)\n",
    "    assert helpful_eq(np.mean(X_train, axis=1)[0], 62.12441680772882)\n",
    "    assert helpful_eq(np.mean(X_test, axis=1)[0], 53.21256512320771)\n",
    "    assert helpful_eq(np.mean(X_train), 57.90520707104668)\n",
    "    assert helpful_eq(np.mean(X_test), 58.20296278479702)\n",
    "\n",
    "test_mean_impute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7sn7kqMIJEc"
   },
   "source": [
    "## Choose $k$ components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8z_ynjlyy8_"
   },
   "source": [
    "### Exercise 5: implement `only_num`\n",
    "\n",
    "We want to perform PCA on only the numerical part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DM6IiF40aNmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50610e+01 2.21970e+01 9.27830e+01 ... 1.55000e-01 2.81000e-01\n",
      "  8.90000e-02]\n",
      " [2.18410e+01 2.07990e+01 1.28829e+02 ... 2.21000e-01 2.36000e-01\n",
      "  7.50000e-02]\n",
      " [1.33840e+01 1.89070e+01 9.37420e+01 ... 1.79000e-01 3.30000e-01\n",
      "          nan]\n",
      " ...\n",
      " [1.93810e+01         nan         nan ... 2.46000e-01 3.55000e-01\n",
      "  7.90000e-02]\n",
      " [1.53530e+01 2.22540e+01 1.02181e+02 ... 1.30000e-01 2.67000e-01\n",
      "  8.00000e-02]\n",
      " [1.57790e+01 1.66350e+01 9.07300e+01 ...         nan 3.24000e-01\n",
      "  8.30000e-02]]\n"
     ]
    }
   ],
   "source": [
    "def only_num(X, non_num_idx):\n",
    "    \"\"\"The columns of numpy.ndarray `X` whose indices are stored in `non_num_idx` are not \n",
    "    numerical. Return a modified copy of `X` that does _not_ contain these columns.\"\"\"\n",
    "    \n",
    "    return np.delete(X, non_num_idx, axis=1)\n",
    "\n",
    "print(only_num(X_train, non_num_idx).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cp5Fgq8VaPw3"
   },
   "outputs": [],
   "source": [
    "def test_only_num():\n",
    "    X = np.array([[-1, 0, 1, 2],\n",
    "                  [-3, 1, 4, 5]])\n",
    "    assert helpful_eq(only_num(X, [1]), np.array([[-1, 1, 2],\n",
    "                                                  [-3, 4, 5]]))\n",
    "    big_X, big_y, non_num_idx = create_big_X_y()\n",
    "    first_num_idx = min([i for i in range(big_X.shape[1]) if i not in non_num_idx])\n",
    "    assert helpful_eq(only_num(big_X, non_num_idx)[0:2, 0], big_X[0:2, first_num_idx])\n",
    "\n",
    "\n",
    "test_only_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBX-zM_nwY8y"
   },
   "source": [
    "### Question 5: what is a good number of principal components to continue with _and why_? (Base your answer only on `X_train`.)\n",
    "\n",
    "A figure may be useful.\n",
    "\n",
    "The amount of variance expressed in each component is given by the r-squared value, with the total of all r-squared adding up to 1. If we want to have the optimum number of principal components, we should plot an elbow plot and look where the elbow makes its sharpest turn.\n",
    "\n",
    "This can be seen in the above plot to be at k=4, or about 63% of the total R_squared value. From this we conclude that a good number of principal components to continue with is 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "X_train, _ = mean_impute(X_train, X_test)\n",
    "pca_dict = pca(only_num(X_train, non_num_idx), k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dt2uDOTJI0RL",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(0,30):\n",
    "    X_train, _ = mean_impute(X_train, X_test)\n",
    "    pca_dict = pca(only_num(X_train, non_num_idx), k)\n",
    "    plt.scatter(np.sum(pca_dict.get(\"R_squared\")[:k])/1*100, pca_dict.get(\"R_squared\")[k])\n",
    "\n",
    "plt.title(\"Percentage of total R_squared value summed until certain value vs value of R_squared\")\n",
    "plt.xlabel(\"R_squared value summed until value k (%)\")\n",
    "plt.ylabel(\"R_squared\")\n",
    "plt.axvline(x=62.85, label=\"elbow position, 63%\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FU6jqajtQ-Us",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000004\n",
      "[0.37696996 0.16513115 0.08512599 0.06068536 0.05325003 0.03891505\n",
      " 0.02426658 0.01902658 0.01621124 0.01502651 0.01311184 0.01246551\n",
      " 0.01181788 0.00923181 0.00863735 0.00782403 0.00723858 0.00694721\n",
      " 0.00660765 0.00629406 0.0061532  0.00598381 0.00580004 0.0056339\n",
      " 0.00553828 0.00540737 0.00535648 0.00527602 0.00514875 0.0049178 ]\n"
     ]
    }
   ],
   "source": [
    "print(sum(pca_dict.get(\"R_squared\")))\n",
    "print(pca_dict.get(\"R_squared\"))\n",
    "\n",
    "#for key in pca_dict.keys():\n",
    "    #print(key)\n",
    "    #print(pca_dict[key].round(4))\n",
    "    #print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9505SsXZIfgX"
   },
   "source": [
    "## Replace `X`'s numerical features with score matrix\n",
    "\n",
    "`X` has many numerical features and a couple of others, whose indices are storen in `non_num_idx`. We only performed PCA on the numerical features. We want to re-group the outcome of the PCA and the non-numerical part of `X` again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWSUlbvdzEI4"
   },
   "source": [
    "### Exercise 6: implement `replace_num_with_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     1.    15.061 ...  0.155  0.281  0.089]\n",
      " [ 0.     0.    21.841 ...  0.221  0.236  0.075]\n",
      " [ 0.     1.    13.384 ...  0.179  0.33   0.084]\n",
      " ...\n",
      " [ 0.     0.    19.381 ...  0.246  0.355  0.079]\n",
      " [ 1.     0.    15.353 ...  0.13   0.267  0.08 ]\n",
      " [ 0.     1.    15.779 ...  0.114  0.324  0.083]]\n",
      "[[ 9.074300e+01  2.771400e+01 -2.588000e+01 ...  2.000000e-03\n",
      "  -1.000000e-03 -1.000000e-03]\n",
      " [ 1.412051e+03  1.145350e+02 -5.490700e+01 ... -1.000000e-03\n",
      "  -2.000000e-03  0.000000e+00]\n",
      " [ 1.699500e+01 -9.681000e+00 -2.282800e+01 ... -3.000000e-03\n",
      "   2.000000e-03 -2.000000e-03]\n",
      " ...\n",
      " [ 6.623080e+02  1.008000e+02 -2.514100e+01 ...  1.000000e-03\n",
      "  -2.000000e-03 -0.000000e+00]\n",
      " [-1.573000e+00  8.654000e+01 -1.633000e+00 ...  3.000000e-03\n",
      "   1.000000e-03 -2.000000e-03]\n",
      " [-1.488510e+02 -3.203800e+01  7.934000e+00 ... -1.000000e-03\n",
      "   3.000000e-03 -2.000000e-03]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 29 is out of bounds for axis 1 with size 29",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10536\\2491074705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace_num_with_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_num_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10536\\2491074705.py\u001b[0m in \u001b[0;36mreplace_num_with_score\u001b[1;34m(X, non_num_idx, score)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mmod_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mmod_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmod_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 29 is out of bounds for axis 1 with size 29"
     ]
    }
   ],
   "source": [
    "def replace_num_with_score(X, non_num_idx, score):\n",
    "    \"\"\"The columns of numpy.ndarray `X` whose indices are stored in `non_num_idx` are not \n",
    "    numerical. Return a modified copy of `X` that has unchanged non-numerical features but in \n",
    "    which the numerical features are replaced by the elements of the `score` numpy.ndarray.\"\"\"\n",
    "    # Assume only first features can be non-numerical to make our life easier\n",
    "    assert all([i == non_num_idx[i] for i in range(len(non_num_idx))])\n",
    "    #Modify X first \n",
    "    mod_X = np.zeros([X.shape[0], X.shape[1]])\n",
    "    score_array = (np.array(score))\n",
    "    j = 0 #counter variable\n",
    "    for i in range(0, X.shape[1]):\n",
    "        if i in non_num_idx:\n",
    "            mod_X[:,i] = X[:,i]\n",
    "        else:\n",
    "            mod_X[:,i] = score_array[:,j]\n",
    "            j = j + 1\n",
    "    return mod_X\n",
    "    \n",
    "print(X_train.round(3))\n",
    "print(pca_dict['score'].round(3))\n",
    "print(replace_num_with_score(X_train, non_num_idx, pca_dict['score']).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gYBfiJjJymPn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_replace_num_with_score():\n",
    "    X = np.array([[1, 2.1, 4.3],\n",
    "                  [0, 4.2, 5.3]])\n",
    "    X = replace_num_with_score(X, [0], [[0,  1], [3,  2]])\n",
    "    assert helpful_eq(X, [[1, 0, 1], [0, 3, 2]])\n",
    "    X = np.array([[1, 2.1, 4.3]])\n",
    "    X = replace_num_with_score(X, [0, 1], [[50]])\n",
    "    assert helpful_eq(X, [[1, 2.1, 50]])\n",
    "\n",
    "\n",
    "test_replace_num_with_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtlLJsden54T"
   },
   "source": [
    "## Wrap pre-processing in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "auwFezgnskoP"
   },
   "outputs": [],
   "source": [
    "def preprocess(X_train, X_test, non_num_idx, pca_k=False):\n",
    "    \"\"\"Returns modified copies of `X_train` and `X_test` in which at least the missing values are\n",
    "    imputed. If `pca_k` is not False but a positive integer, perform PCA as above, and replace\n",
    "    numerical features (column indices not in `non_num_idx` with elements of the score matrix.\n",
    "    The outcome of the `pca` function is returned as third value, or `None` if no PCA is done.\"\"\"\n",
    "    X_train, X_test = mean_impute(X_train, X_test)\n",
    "    if pca_k > 0:\n",
    "        pca_dict = pca(only_num(X_train, non_num_idx), pca_k)\n",
    "        X_train_with_score = replace_num_with_score(X_train, non_num_idx, pca_dict['score'])\n",
    "        X_test_s = score_new_data(only_num(X_test, non_num_idx), pca_dict['orig_center'], \n",
    "                                  pca_dict['orig_std'], pca_dict['components'])\n",
    "        X_test_with_score = replace_num_with_score(X_test, non_num_idx, X_test_s)\n",
    "        return X_train_with_score, X_test_with_score, pca_dict\n",
    "    else:\n",
    "        return X_train, X_test, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YInpizUMskoQ"
   },
   "source": [
    "## Evaluate PCA as part of pre-processing\n",
    "\n",
    "We will use repeated cross validation with https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html fit to and predicting exactly the same data. By \"repeated\", we mean performing `n_repeats` divisions of the data into `n_folds` and having each of these folds as test set once. Compared to doing cross validation just once, this gives a stabler estimate of computation time and accuracy/loss. We are interested in estimating and comparing both of these quantities. To do that fairly, we use the same data splitting and model fitting seeds.\n",
    "\n",
    "We will use the IPython magic command `%%time` in the beginning of a cell to see the time it -- the cell -- takes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XYBP-XH8skoQ"
   },
   "outputs": [],
   "source": [
    "n_repeats = n_folds = 2  # you may want to lower this to, e.g., 2 while working on the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxHpSMj8zpmu"
   },
   "source": [
    "### Exercise 7: implement `repeated_cross_validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JZIzslpOO-bx"
   },
   "outputs": [],
   "source": [
    "def repeated_cross_validation(X, y, n_repeats, n_folds, non_num_idx, pca_k=False):\n",
    "    \"\"\"For i = 0, ...`n_repeats`, create `X` and `y` folds with seed i. Then perform regular\n",
    "    cross validation per set of folds. This regular CV includes \n",
    "    `preprocess(X_train, X_test, non_num_idx, pca_k)` and training an\n",
    "    `SVC(random_state=(i+1)*(j+1))` where `j` is the index of the test fold. Return an \n",
    "    `n_repeats`-by-`n_folds` numpy.ndarray of mean accuracies per test fold.\"\"\"\n",
    "    j = 0 # counter variable for n_folds \n",
    "    X_train = np.empty([n_repeats, n_folds,int(X.shape[0]/n_folds), X.shape[1]]) #dim repeats x folds x X x y \n",
    "    X_test = X_train\n",
    "    y_train = np.empty([n_repeats, n_folds,int(X.shape[0]/n_folds)])\n",
    "    y_test = y_train\n",
    "    for i in range(0, n_repeats):\n",
    "        #Create X,y folds \n",
    "        for j in range(0, n_folds):\n",
    "            X_train[i,j,:,:],X_test[i,j,:,:],y_train[i,j,:],y_test[i,j,:]=NFolds(X, y, n_folds = n_folds, seed=i).get_fold(j)\n",
    "            #a,b,c,d = NFolds(X, y, n_folds = n_folds, seed=i).get_fold(j)]\n",
    "\n",
    "    #Preprocess and perform SVC\n",
    "    for i in range(0, n_repeats):\n",
    "        for l in range(0, n_folds):\n",
    "            X_train1, X_test1 = preprocess(X_train[i,l,:,:],X_test[i,l,:,:], non_num_idx, pca_k)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DmbrlgJ9ymPm",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16336\\513852114.py\u001b[0m in \u001b[0;36mrepeated_cross_validation\u001b[1;34m(X, y, n_repeats, n_folds, non_num_idx, pca_k)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_num_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16336\\2676950074.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(X_train, X_test, non_num_idx, pca_k)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpca_k\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpca_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monly_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_num_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mX_train_with_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplace_num_with_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_num_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         X_test_s = score_new_data(only_num(X_test, non_num_idx), pca_dict['orig_center'], \n\u001b[0;32m     11\u001b[0m                                   pca_dict['orig_std'], pca_dict['components'])\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16336\\2491074705.py\u001b[0m in \u001b[0;36mreplace_num_with_score\u001b[1;34m(X, non_num_idx, score)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mmod_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mmod_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmod_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 5\n",
    "accuracies_pca = repeated_cross_validation(big_X, big_y, n_repeats, n_folds, non_num_idx, pca_k=k)\n",
    "#print(accuracies_pca.round(3))\n",
    "#print(f'Accuracy with PCA: {round(np.mean(accuracies_pca), 3)}' +\n",
    "      #f'+- {round(np.std(accuracies_pca), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "s5joVCisIdRf",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repeated_cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10536\\2763496865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtest_repeated_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10536\\2763496865.py\u001b[0m in \u001b[0;36mtest_repeated_cross_validation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_mean_impute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnn_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepeated_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     assert helpful_eq(accuracies, [[0.91549296, 0.89824561],\n\u001b[0;32m      7\u001b[0m                                    [0.9084507,  0.91578947]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'repeated_cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "def test_repeated_cross_validation():\n",
    "    X, y = load_breast_cancer(return_X_y=True)\n",
    "    test_mean_impute()\n",
    "    nn_idx = []\n",
    "    accuracies = repeated_cross_validation(X, y, 2, 2, nn_idx, pca_k=False)\n",
    "    assert helpful_eq(accuracies, [[0.91549296, 0.89824561],\n",
    "                                   [0.9084507,  0.91578947]])\n",
    "    accuracies_pca = repeated_cross_validation(X, y, 2, 2, nn_idx, pca_k=2)\n",
    "    assert helpful_eq(accuracies_pca, [[0.91549296, 0.92631579],\n",
    "                                       [0.92605634, 0.93684211]])\n",
    "    X, y = load_breast_cancer(return_X_y=True)\n",
    "    test_mean_impute()\n",
    "    nn_idx = [0, 1, 2]\n",
    "    accuracies = repeated_cross_validation(X, y, 4, 3, nn_idx, pca_k=False)\n",
    "    assert helpful_eq(np.array(accuracies).shape, (4, 3))\n",
    "    assert helpful_eq(accuracies, [[0.92592593, 0.89473684, 0.91052632],\n",
    "                                   [0.8994709,  0.89473684, 0.92105263],\n",
    "                                   [0.91005291, 0.89473684, 0.92631579],\n",
    "                                   [0.92592593, 0.91052632, 0.91052632]])\n",
    "    accuracies_pca = repeated_cross_validation(X, y, 4, 3, nn_idx, pca_k=2)\n",
    "    assert helpful_eq(accuracies_pca, [[0.92063492, 0.88947368, 0.91578947],\n",
    "                                       [0.88888889, 0.9,        0.9       ],\n",
    "                                       [0.8994709,  0.92105263, 0.9       ],\n",
    "                                       [0.93121693, 0.87894737, 0.91052632]])\n",
    "\n",
    "\n",
    "test_repeated_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "5mMOJ6BIn54U",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repeated_cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'repeated_cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies = repeated_cross_validation(big_X, big_y, n_repeats, n_folds, non_num_idx)\n",
    "print(accuracies.round(3))\n",
    "print(f'Accuracy without PCA: {round(np.mean(accuracies), 3)}' +\n",
    "      f'+- {round(np.std(accuracies), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkqSXNyxymPp"
   },
   "source": [
    "### Question 6: how do the computation time and accuracies differ between the repeated evaluations with and without PCA, and how do you explain this?\n",
    "\n",
    "If you use a different $k$ than you chose in question 5, specify it. We only looked at one specific training set in Q5, so your answer there is not necessarily wrong if you pick something else here.\n",
    "\n",
    "The calculations with PCA tend to be faster, which is explained by the fact that the PCA simplifices the dataset by reducing the dimension, so that less complex computation is required. The accuracy is lower though, which is the cost of this simplification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhKKG0LeAHeu"
   },
   "source": [
    "### Question 7 (bonus): test your theory.\n",
    "\n",
    "You may include _relevant_ (psuedo-)code and figures in your report. It's fine if you (partially) falsify your theory too, as long as it -- the theory -- made sense in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asNmOF_FAH4G"
   },
   "source": [
    "### Question 8: can you describe a situation where (or model for which) PCA would not help?\n",
    "\n",
    "A situation where PCA would not help is a dataset where one would expect the different features not to be related. As PCA reduces the dimension of a dataset by calculating a relation between the different features, it does not make sense to do so where there are no relations expected to be found, and might even cause the model to lose efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0VKGRXxLoEF"
   },
   "source": [
    "## Interpret principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "915cw7gkymPp"
   },
   "source": [
    "### Question 9: make scatterplots of 1: (train/test/all) points expressed in terms of the first two principal components; 2: the first two numerical features.\n",
    "\n",
    "Make sure the labels of the points are displayed somehow, so that we can get a rough idea of how well the malignant and benign samples can be distinguished using only the first two principal components.\n",
    "\n",
    "This requires you to run PCA with $k \\geq 2$, but you could use https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html on this dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-DBIcW-In54W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c987ade288>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 471x68318 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2323\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2324\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2325\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   2326\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2327\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 **kwargs)\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[1;33m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \"\"\"\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         mpl.image.imsave(\n\u001b[0;32m    542\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;31m# docstring inherited\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[1;31m# Acquire a lock on the shared font cache.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_renderer\u001b[1;34m(self, cleared)\u001b[0m\n\u001b[0;32m    445\u001b[0m                           and getattr(self, \"_lastKey\", None) == key)\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreuse_renderer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lastKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcleared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, dpi)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_renderers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Image size of 471x68318 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "big_X, big_y, non_num_idx = create_big_X_y()\n",
    "X_train, X_test, y_train, y_test = NFolds(big_X, big_y, seed=5).get_fold(0)\n",
    "X_train, X_test = mean_impute(X_train, X_test)\n",
    "\n",
    "k = 2\n",
    "pca = PCA(n_components = k)\n",
    "mod_X_train = pca.fit_transform(X_train)\n",
    "mod_X_score = pca.transform(X_test)\n",
    "for i in range(0, mod_X_train.shape[0]):\n",
    "    plt.scatter(mod_X_train[i,0], mod_X_train[i,1], label=\"training points\", c=r)\n",
    "for i in range(0, mod_X_test.shape[0])\n",
    "    plt.scatter(mod_X_score[i,0], mod_X_train[i,1], label=\"test points\", c=b)\n",
    "plt.title(\"Plot of the dataset expressed in terms of the first two principal components\")\n",
    "plt.xlabel(\"k_0\")\n",
    "plt.ylabel(\"k_1\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBXDGoMUO-b1"
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "GkaLzfDOymPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 [0.005 0.004]\n",
      "01 [0.002 0.   ]\n",
      "02 [0.032 0.026]\n",
      "03 [0.488 0.87 ]\n",
      "04 [ 0. -0.]\n",
      "05 [0. 0.]\n",
      "06 [0. 0.]\n",
      "07 [0. 0.]\n",
      "08 [ 0. -0.]\n",
      "09 [-0. -0.]\n",
      "10 [0. 0.]\n",
      "11 [-0.  0.]\n",
      "12 [0.002 0.001]\n",
      "13 [0.049 0.021]\n",
      "14 [-0. -0.]\n",
      "15 [0. 0.]\n",
      "16 [0. 0.]\n",
      "17 [0. 0.]\n",
      "18 [-0.  0.]\n",
      "19 [-0. -0.]\n",
      "20 [0.006 0.003]\n",
      "21 [ 0.003 -0.001]\n",
      "22 [0.044 0.021]\n",
      "23 [ 0.87  -0.492]\n",
      "24 [ 0. -0.]\n",
      "25 [ 0. -0.]\n",
      "26 [0. 0.]\n",
      "27 [0. 0.]\n",
      "28 [ 0. -0.]\n",
      "29 [ 0. -0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pca_dict['components'].shape[1]):\n",
    "    print(\"{:02d}\".format(i), pca_dict['components'][:2, i].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xhn5VCXwymPq"
   },
   "source": [
    "### Question 10 (2 points): what do the (first two) principal components represent when you think back to what the numerical features are based on?\n",
    "\n",
    "Those represent the features with the two highest variances. For this dataset, those features are number 6 and 26; which correspond to the mean of the compactness and the mean of the three largest concavities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1MOASrRLtCv"
   },
   "source": [
    "## Reconstruct numerical features from score matrix\n",
    "\n",
    "Finally, we want to reconstruct our numerical data on its original scale from its score. PCA with $k \\ll d$ is not supposed to be lossless (i.e., perfect) compression, so our results might not look great, but this is a nice exercise.\n",
    "\n",
    "This may seem more daunting than the other programming exercises but it is just a combination of things we have done before. The docstring contains an outline, and the first case in the `test_` function might help as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzk5tb5yD286"
   },
   "source": [
    "### Exercise 8: implement `approx_X_from_X_with_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK4tRYtNymPo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def approx_X_from_X_with_score(X_with_score, pca_dict, non_num_idx):\n",
    "    \"\"\"Obtain the score matrix from the `non_num_idx` columns of `X_with_score`. Then reconstruct\n",
    "    the feature values they originally represented using the PCA outcome stored in `pca_dict`. \n",
    "    Return these values in the same format as the original matrix, without forgetting the \n",
    "    `non_num_idx` columns.\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "_, X_test_with_score, pca_dict = preprocess(X_train, X_test, non_num_idx, pca_k=2)\n",
    "X_test_reconstr = approx_X_from_X_with_score(X_test_with_score, pca_dict, non_num_idx)\n",
    "print(X_test[0].round(3))\n",
    "print(X_test_reconstr[0].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouzapTMUFG2n"
   },
   "outputs": [],
   "source": [
    "def test_approx_X_from_X_with_score():\n",
    "    X_train = np.array([[0.0, 0.4], \n",
    "                        [1.0, 1.6], \n",
    "                        [2.0, 3.4], \n",
    "                        [3.0, 4.6]])\n",
    "    X_test = np.array([[4, 5.6]])\n",
    "    non_num_idx = []\n",
    "    _, X_test_w_score, pca_dict = preprocess(X_train, X_test, non_num_idx, pca_k=1)\n",
    "    assert helpful_eq(X_test_w_score, [[2.93797197]])\n",
    "    # ^ tests only if mistake is in previous functions\n",
    "    X_test_reconstr = approx_X_from_X_with_score(X_test_w_score, pca_dict, non_num_idx)\n",
    "    assert helpful_eq(X_test_reconstr, [[3.82267078, 5.85623919]])\n",
    "    assert helpful_eq(mean_squared_error(X_test, X_test_reconstr), 0.04855208630760682)\n",
    "\n",
    "    X, y, non_num_idx = create_big_X_y()\n",
    "    X_train, X_test, y_train, y_test = NFolds(X, y, seed=5).get_fold(0)\n",
    "    X_train, X_test = mean_impute(X_train, X_test)\n",
    "    _, X_test_w_score, pca_dict = preprocess(X_train, X_test, non_num_idx, pca_k=2)\n",
    "    X_test_reconstr = approx_X_from_X_with_score(X_test_w_score, pca_dict, non_num_idx)\n",
    "    assert helpful_eq(X_test_reconstr[0:5, -1], \n",
    "                      [0.07272649, 0.08546382, 0.07856379, 0.07790174, 0.10962264])\n",
    "    assert helpful_eq(mean_squared_error(X_test, X_test_reconstr), 2760.755214107711)\n",
    "\n",
    "\n",
    "test_approx_X_from_X_with_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U84291iuN8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A4.ipynb",
   "provenance": [
    {
     "file_id": "1hhuDArvoI0JkQmeeJY94uOaHonmhUAJr",
     "timestamp": 1618487186541
    },
    {
     "file_id": "13otroaMKy7Ps1w-poN8MkYqXnOf94WUR",
     "timestamp": 1616589967870
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "358px",
    "left": "1210px",
    "right": "20px",
    "top": "158px",
    "width": "606px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
